{"cells":[{"cell_type":"markdown","metadata":{},"source":["<table style=\"border: none\" align=\"left\">\n","   <tr style=\"border: none\">\n","      <th style=\"border: none\"><font face=\"verdana\" size=\"5\" color=\"black\"><b>Build a Loan default PMML scoring model with scikit-learn in Watson ML </b></th>\n","      <th style=\"border: none\"><img src=\"https://github.com/pmservice/customer-satisfaction-prediction/blob/master/app/static/images/ml_icon_gray.png?raw=true\" alt=\"Watson Machine Learning icon\" height=\"40\" width=\"40\"></th>\n","   </tr>\n","</table>"]},{"cell_type":"markdown","metadata":{},"source":["This notebook contains steps and code to get a loan dataset, create a predictive model, and start scoring new data. This notebook introduces commands for getting data and for basic data cleaning and exploration, model creation, model training, model persistence, model deployment, and scoring.\n","\n","Some familiarity with Python is helpful. This notebook uses Python 3.\n","\n","\n","## Learning goals\n","\n","You will learn how to:\n","\n","-  Load a CSV file into a Pandas DataFrame.\n","-  Explore data.\n","-  Prepare data for training and evaluation.\n","-  Create a scikit-learn machine learning model.\n","-  Train and evaluate a model.\n","-  Save the model as PMML file.\n","\n","\n","\n","## Contents\n","\n","This notebook contains the following parts:\n","\n","1.\t[Set up](#setup)\n","2.\t[Load and explore data](#load)\n","3.\t[Create a Scikit learn machine learning model](#model)\n","4.\t[Store the model in Watson Machine Learning provider](#provider)\n","5.\t[Summary and next steps](#summary)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"setup\"></a>\n","## 1. Set up\n","\n","Before you use the sample code in this notebook,you create a <a href=\"https://cloud.ibm.com/catalog?category=ai#services\" target=\"_blank\" rel=\"noopener no referrer\">Watson Machine Learning (WML) Service</a> instance (a lite plan is offered and information about how to create the instance is <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-samples-overview.html\" target=\"_blank\" rel=\"noopener no referrer\">here</a>)\n"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"load\"></a>\n","## 2. Load and explore data"]},{"cell_type":"markdown","metadata":{},"source":["In this section you will load the data as a Pandas DataFrame and perform a basic exploration.\n","\n","Load the data to the Pandas DataFrame by using *wget* to upload the data to gpfs and then use pandas *read* method to read data. "]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting wget\n","  Downloading wget-3.2.zip (10 kB)\n","Building wheels for collected packages: wget\n","  Building wheel for wget (setup.py) ... \u001b[?25ldone\n","\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=a8c514188af46ba2cdb779ed8a52ace7fc6e6cefd3bee4cd7ccde31bcbc9c146\n","  Stored in directory: /home/spark/shared/.cache/pip/wheels/04/5f/3e/46cc37c5d698415694d83f607f833f83f0149e49b3af9d0f38\n","Successfully built wget\n","Installing collected packages: wget\n","Successfully installed wget-3.2\n"]}],"source":["# Install wget if you don't already have it.\n","!pip install wget"]},{"cell_type":"code","execution_count":2,"metadata":{"scrolled":false},"outputs":[{"name":"stdout","output_type":"stream","text":["miniloan-payment-default-cases-v2.0.csv\n"]}],"source":["import wget\n","link_to_data = 'https://raw.githubusercontent.com/ODMDev/decisions-on-spark/master/data/miniloan/miniloan-payment-default-cases-v2.0.csv'\n","filename = wget.download(link_to_data)\n","\n","print(filename)"]},{"cell_type":"markdown","metadata":{},"source":["Import required libraires to create our Panda DataFrame"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{},"source":["Load the file to Pandas DataFrame using code below"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["used_names = ['creditScore', 'income', 'loanAmount', 'monthDuration', 'rate', 'yearlyReimbursement', 'paymentDefault']\n","\n","df = pd.read_csv(\n","    filename,\n","    header=0,\n","    delimiter=r'\\s*,\\s*',\n","    engine='python'\n",").replace(\n","    [np.inf, -np.inf], np.nan\n",").dropna().loc[:, used_names]"]},{"cell_type":"markdown","metadata":{},"source":["Explore the loaded data by using the following Pandas DataFrame methods:\n","-  print types\n","-  print top ten records\n","-  count all records"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["creditScore            float64\n","income                 float64\n","loanAmount             float64\n","monthDuration          float64\n","rate                   float64\n","yearlyReimbursement    float64\n","paymentDefault           int64\n","dtype: object"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["# convert all columns of DataFrame to float to avoid scaler warnings\n","df = df.astype({'creditScore': float, \"income\": np.float64, \"loanAmount\": np.float64, \"monthDuration\": np.float64, \"yearlyReimbursement\": np.float64, \"paymentDefault\": np.int64})\n","df.dtypes"]},{"cell_type":"markdown","metadata":{},"source":["As you can see, the data contains five fields. default field is the one you would like to predict (label)."]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>creditScore</th>\n","      <th>income</th>\n","      <th>loanAmount</th>\n","      <th>monthDuration</th>\n","      <th>rate</th>\n","      <th>yearlyReimbursement</th>\n","      <th>paymentDefault</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>436.0</td>\n","      <td>290532.0</td>\n","      <td>136331.0</td>\n","      <td>19.0</td>\n","      <td>0.08</td>\n","      <td>13979.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>500.0</td>\n","      <td>94722.0</td>\n","      <td>150099.0</td>\n","      <td>20.0</td>\n","      <td>0.08</td>\n","      <td>15091.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>670.0</td>\n","      <td>86878.0</td>\n","      <td>269819.0</td>\n","      <td>21.0</td>\n","      <td>0.08</td>\n","      <td>26947.0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>717.0</td>\n","      <td>274553.0</td>\n","      <td>513754.0</td>\n","      <td>19.0</td>\n","      <td>0.08</td>\n","      <td>53720.0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>471.0</td>\n","      <td>278339.0</td>\n","      <td>206578.0</td>\n","      <td>13.0</td>\n","      <td>0.07</td>\n","      <td>24874.0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   creditScore    income  loanAmount  monthDuration  rate  \\\n","0        436.0  290532.0    136331.0           19.0  0.08   \n","1        500.0   94722.0    150099.0           20.0  0.08   \n","2        670.0   86878.0    269819.0           21.0  0.08   \n","3        717.0  274553.0    513754.0           19.0  0.08   \n","4        471.0  278339.0    206578.0           13.0  0.07   \n","\n","   yearlyReimbursement  paymentDefault  \n","0              13979.0               0  \n","1              15091.0               0  \n","2              26947.0               1  \n","3              53720.0               0  \n","4              24874.0               0  "]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df.head()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of records: 1000\n"]}],"source":["print(\"Number of records: \" + str(len(df)))"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"model\"></a>\n","## 3. Create a Scikit learn machine learning model\n","\n","In this section you will learn how to:\n","\n","- [3.1 Prepare data](#prep)\n","- [3.2 Create a model](#pipe)\n","- [3.3 Train a model](#train)\n","- [3.4 Save as PMML file](#save)\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3.1 Prepare data<a id=\"prep\"></a>\n","\n","In this subsection you will split your data into: \n","- train data set\n","- test data set\n","- predict data set"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of training records: 800\n","Number of testing records : 180\n","Number of prediction records : 20\n"]}],"source":["splitted_data = np.split(df.sample(frac=1, random_state=42), [int(.8*len(df)), int((.8+.18)*len(df))])\n","train_data = splitted_data[0]\n","test_data = splitted_data[1]\n","predict_data = splitted_data[2]\n","\n","print(\"Number of training records: \" + str(len(train_data)))\n","print(\"Number of testing records : \" + str(len(test_data)))\n","print(\"Number of prediction records : \" + str(len(predict_data)))"]},{"cell_type":"markdown","metadata":{},"source":["As you can see your data has been successfully split into three data sets: \n","\n","-  The train data set, which is the largest group, is used for training.\n","-  The test data set will be used for model evaluation and is used to test the assumptions of the model.\n","-  The predict data set will be used for prediction."]},{"cell_type":"markdown","metadata":{},"source":["### 3.2 Create a ML model and pipeline<a id=\"pipe\"></a>\n","\n","In this section you will create a Scikit-Learn machine learning model and then train the model.\n","\n","In the first step you need to import the Scikit-Learn machine learning packages that will be needed in the subsequent steps."]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import SGDClassifier\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"markdown","metadata":{},"source":["Now construct the model. A linear model with Stochastic Gradient Descent is used in the following example. We use a pipeline to add an input scaling step."]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["clf = SGDClassifier(loss=\"log\", penalty=\"l2\", random_state=42, tol=1e-3)\n","scaler = StandardScaler()"]},{"cell_type":"markdown","metadata":{},"source":["You then create a simple pipeline to first scale the input parameter values and then apply the model."]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["from sklearn.pipeline import Pipeline\n","\n","pipeline = Pipeline([\n","    ('standardize', scaler),\n","    (\"classifier\", clf)\n","])"]},{"cell_type":"markdown","metadata":{},"source":["### 3.3 Train the model<a id=\"train\"></a>\n","Now, you can train your Random Forest model by using the previously defined **pipeline** and **train data**."]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"data":{"text/plain":["creditScore            float64\n","income                 float64\n","loanAmount             float64\n","monthDuration          float64\n","rate                   float64\n","yearlyReimbursement    float64\n","paymentDefault           int64\n","dtype: object"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["train_data.dtypes"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["x_train_data = train_data.loc[:, used_names[:-1]]\n","y_train_data = train_data.loc[:, used_names[-1]]"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["pipeline.fit(x_train_data, y_train_data)\n","\n","# we defined a variable trainedAt to keep track of when the model was trained\n","import datetime;\n","ts = datetime.datetime.now()\n","trainedAt = ts.strftime(\"%Y-%m-%dT%H:%M:%S.000Z\")"]},{"cell_type":"markdown","metadata":{},"source":["You can check your **model accuracy** now. Use **test data** to evaluate the model."]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["x_test_data = test_data.loc[:, used_names[:-1]]\n","y_test_data = test_data.loc[:, used_names[-1]]\n","\n","predictions = pipeline.predict(x_test_data)"]},{"cell_type":"markdown","metadata":{},"source":["We define a **metrics** variable to keep track of the metrics values"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Coefficient of determination R^2 on test data = 0.9666666666666667\n","Root Mean Squared Error (RMSE) on test data = 0.03333333333333333\n","Accuracy on test data = 0.9666666666666667\n","Balanced accuracy on test data = 0.9375\n","Confusion Matrix on test data = [[132, 0], [6, 42]]\n"]}],"source":["from sklearn.metrics import mean_squared_error, classification_report, balanced_accuracy_score, accuracy_score, confusion_matrix\n","\n","metrics = []\n","\n","name = \"Coefficient of determination R^2\"\n","r2 = pipeline.score(x_test_data, y_test_data)\n","metrics.append({ \"name\": name, \"value\": r2 })\n","\n","name = \"Root Mean Squared Error (RMSE)\"\n","rmse = mean_squared_error(y_test_data, predictions)\n","metrics.append({ \"name\": name, \"value\": rmse })\n","\n","name = \"Accuracy\"\n","acc = accuracy_score(y_test_data, predictions)\n","metrics.append({ \"name\": name, \"value\": acc })\n","\n","name = \"Balanced accuracy\"\n","balanced_acc = balanced_accuracy_score(y_test_data, predictions)\n","metrics.append({ \"name\": name, \"value\": balanced_acc })\n","\n","name = \"Confusion Matrix\"\n","confusion_mat = confusion_matrix(y_test_data, predictions, labels=[0, 1])\n","metrics.append({ \"name\": name, \"value\": str(confusion_mat.tolist()) })\n","\n","for metric in metrics:\n","    print(metric[\"name\"], \"on test data =\", metric[\"value\"])"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.96      1.00      0.98       132\n","           1       1.00      0.88      0.93        48\n","\n","    accuracy                           0.97       180\n","   macro avg       0.98      0.94      0.96       180\n","weighted avg       0.97      0.97      0.97       180\n","\n"]}],"source":["print(classification_report(y_test_data, predictions))"]},{"cell_type":"markdown","metadata":{},"source":["### 3.4 Save as pmml file <a id=\"save\"></a>"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting nyoka==4.3.0\n","  Downloading nyoka-4.3.0-py3-none-any.whl (336 kB)\n","\u001b[K     |████████████████████████████████| 336 kB 17.0 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: lxml in /opt/ibm/conda/miniconda3.9/lib/python3.9/site-packages (from nyoka==4.3.0) (4.7.1)\n","Installing collected packages: nyoka\n","Successfully installed nyoka-4.3.0\n"]}],"source":["!pip install nyoka==4.3.0"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["ML-Sample-SGDClassifier-StandardScaler-pmml.xml\n"]}],"source":["model_name = type(clf).__name__\n","scaler_name = type(scaler).__name__\n","\n","from nyoka import skl_to_pmml\n","features=x_train_data.columns\n","target=\"paymentDefault\"\n","pmml_filename = \"ML-Sample-\" + model_name + '-' + scaler_name + \"-pmml.xml\"\n","skl_to_pmml(pipeline, features, target, pmml_filename)\n","print(pmml_filename)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"provider\"></a>\n","## 4. Store the model in Watson Machine Learning Provider\n"]},{"cell_type":"markdown","metadata":{},"source":["In this section you will learn how to use Python client libraries to store your pipeline and model in WML repository.\n","\n","- [4.1 Import the libraries](#lib)\n","- [4.2 Save model](#save)\n","- [4.3 Invoke model](#local)"]},{"cell_type":"markdown","metadata":{},"source":["### 4.1 Import the libraries<a id=\"lib\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["Authenticate to the Watson Machine Learning service on IBM Cloud.\n","\n","**Tip**: Authentication information (your credentials) can be found in the <a href=\"https://cloud.ibm.com/iam/apikeys\" target=\"_blank\" rel=\"noopener no referrer\">Service credentials</a> tab of the service instance that you created on IBM Cloud. \n","\n","If you cannot see the **instance_id** field in **Service Credentials**, click **New credential (+)** to generate new authentication information. \n","\n","**Action**: Enter your Watson Machine Learning service instance credentials here."]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["from ibm_watson_machine_learning import APIClient\n","\n","wml_credentials = {\n","                   \"url\": \"URL TO BE SET\",  # example: \"https://eu-gb.ml.cloud.ibm.com\"\n","                   \"apikey\":\"PASTE YOUR API KEY HERE\"\n","                  }\n","\n","client = APIClient(wml_credentials)"]},{"cell_type":"markdown","metadata":{},"source":["### 4.2 Save the pipeline and deploy model<a id=\"save\"></a>"]},{"cell_type":"markdown","metadata":{},"source":["In this subsection you will learn how to save pipeline and model artifacts to your Watson Machine Learning instance."]},{"cell_type":"markdown","metadata":{},"source":["First, you need to create a space that will be used for deploying models. If you do not have space already created, you can use  <a href=\"https://dataplatform.cloud.ibm.com/ml-runtime/spaces?context=cpdaas\" target=\"_blank\" rel=\"noopener no referrer\">Deployment Spaces Dashboard</a> to create one.\n","\n","- Click New Deployment Space\n","- Create an empty space\n","- Select Cloud Object Storage\n","- Select Watson Machine Learning instance and press Create\n","- Copy space_id and paste it below"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["'SUCCESS'"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["space_id ='PASTE YOUR SPACE ID HERE'\n","client.set.default_space(space_id)"]},{"cell_type":"markdown","metadata":{},"source":["Publish model directly from pipeline."]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["input_data_schema={\n","    'id': '1', \n","    'type': 'struct', \n","    'fields': [\n","        {  \n","            'name': 'creditScore',\n","            'nullable': True,\n","            'type': 'float64'\n","        },\n","        {   \n","            'name': 'income',\n","            'nullable': True,\n","            'type': 'float64'\n","        },\n","        {   \n","            'name': 'loanAmount',\n","            'nullable': True,\n","            'type': 'float64'\n","        },\n","        {   \n","            'name': 'monthDuration',\n","            'nullable': True,\n","            'type': 'float64'\n","        },\n","        {  \n","            'name': 'rate',\n","            'nullable': True,\n","            'type': 'float64'\n","        },\n","        {   \n","            'name': 'yearlyReimbursement',\n","            'nullable': True,\n","            'type': 'float64'\n","        }\n","]}"]},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["sofware_spec_uid = client.software_specifications.get_id_by_name(\"spark-mllib_3.0\")\n","\n","metadata = {\n","            client.repository.ModelMetaNames.NAME: 'Payment Default - PMML',\n","            client.repository.ModelMetaNames.TYPE: 'pmml_4.3',\n","            client.repository.ModelMetaNames.INPUT_DATA_SCHEMA: input_data_schema,\n","            client.repository.ModelMetaNames.SOFTWARE_SPEC_UID: sofware_spec_uid,\n","            client.repository.ModelMetaNames.LABEL_FIELD: 'paymentDefault',\n","\n","}\n","\n","published_model_details = client.repository.store_model(model=pmml_filename, meta_props=metadata)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["This method is deprecated, please use get_model_id()\n","model_uid:  e626b6d0-7021-48db-8f6b-c47c59702cc9\n"]}],"source":["model_uid = client.repository.get_model_uid( published_model_details )\n","\n","print( \"model_uid: \", model_uid )"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","\n","#######################################################################################\n","\n","Synchronous deployment creation for uid: 'e626b6d0-7021-48db-8f6b-c47c59702cc9' started\n","\n","#######################################################################################\n","\n","\n","initializing\n","Note: online_url is deprecated and will be removed in a future release. Use serving_urls instead.\n","\n","ready\n","\n","\n","------------------------------------------------------------------------------------------------\n","Successfully finished deployment creation, deployment_uid='44fa30c0-be29-4348-bf85-5cdf487215ed'\n","------------------------------------------------------------------------------------------------\n","\n","\n","scoring_endpoint:  https://us-south.ml.cloud.ibm.com/ml/v4/deployments/44fa30c0-be29-4348-bf85-5cdf487215ed/predictions\n"]}],"source":["deployment_name  = \"Payment Default deployment\"\n","deployment_desc  = \"Online deployment of Loan payment default predictive service in pmml\"\n","deployment_metadata = {\n","                        client.deployments.ConfigurationMetaNames.NAME: deployment_name, \n","                        client.deployments.ConfigurationMetaNames.DESCRIPTION: deployment_desc,\n","                        client.deployments.ConfigurationMetaNames.ONLINE: {}\n","}\n","deployment       = client.deployments.create(artifact_uid=model_uid, meta_props=deployment_metadata)\n","scoring_endpoint = client.deployments.get_scoring_href( deployment )\n","print( \"scoring_endpoint: \", scoring_endpoint )"]},{"cell_type":"markdown","metadata":{},"source":["**Tip**: Use `client.repository.ModelMetaNames.show()` to get the list of available props."]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["------------------------  ----  --------  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n","META_PROP NAME            TYPE  REQUIRED  SCHEMA\n","NAME                      str   Y\n","DESCRIPTION               str   N\n","INPUT_DATA_SCHEMA         list  N         {'id(required)': 'string', 'fields(required)': [{'name(required)': 'string', 'type(required)': 'string', 'nullable(optional)': 'string'}]}\n","TRAINING_DATA_REFERENCES  list  N         [{'name(optional)': 'string', 'type(required)': 'string', 'connection(required)': {'endpoint_url(required)': 'string', 'access_key_id(required)': 'string', 'secret_access_key(required)': 'string'}, 'location(required)': {'bucket': 'string', 'path': 'string'}, 'schema(optional)': {'id(required)': 'string', 'fields(required)': [{'name(required)': 'string', 'type(required)': 'string', 'nullable(optional)': 'string'}]}}]\n","OUTPUT_DATA_SCHEMA        dict  N         {'id(required)': 'string', 'fields(required)': [{'name(required)': 'string', 'type(required)': 'string', 'nullable(optional)': 'string'}]}\n","LABEL_FIELD               str   N\n","TRANSFORMED_LABEL_FIELD   str   N\n","TAGS                      list  N         ['string', 'string']\n","SIZE                      dict  N         {'in_memory(optional)': 'string', 'content(optional)': 'string'}\n","PIPELINE_UID              str   N\n","RUNTIME_UID               str   N\n","TYPE                      str   Y\n","CUSTOM                    dict  N\n","DOMAIN                    str   N\n","HYPER_PARAMETERS          dict  N\n","METRICS                   list  N\n","IMPORT                    dict  N         {'name(optional)': 'string', 'type(required)': 'string', 'connection(required)': {'endpoint_url(required)': 'string', 'access_key_id(required)': 'string', 'secret_access_key(required)': 'string'}, 'location(required)': {'bucket': 'string', 'path': 'string'}}\n","TRAINING_LIB_UID          str   N\n","MODEL_DEFINITION_UID      str   N\n","SOFTWARE_SPEC_UID         str   N\n","TF_MODEL_PARAMS           dict  N\n","------------------------  ----  --------  ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n"]}],"source":["client.repository.ModelMetaNames.show()"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"local\"></a>\n","### 4.3 Invoke model\n"]},{"cell_type":"markdown","metadata":{},"source":["In this subsection you will score the *predict_data* data set.\n","You will learn how to invoke a saved model from a specified instance of Watson Machine Learning."]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[{"data":{"text/plain":["{'predictions': [{'fields': ['probability_0',\n","    'probability_1',\n","    'predicted_paymentDefault'],\n","   'values': [[0.9862080753193663, 0.013791924680633696, 0],\n","    [0.9746109694943419, 0.02538903050565818, 0],\n","    [0.05726872739728228, 0.9427312726027176, 1],\n","    [0.9851147338690263, 0.014885266130973745, 0],\n","    [0.9336931821532308, 0.06630681784676912, 0],\n","    [0.9999999937815078, 6.2184920831632535e-09, 0],\n","    [0.9999989977926816, 1.002207318321187e-06, 0],\n","    [0.999795077318704, 0.00020492268129612448, 0],\n","    [0.7931746237668309, 0.20682537623316907, 0],\n","    [0.9733757854522098, 0.026624214547790237, 0],\n","    [0.9983125902653716, 0.001687409734628524, 0],\n","    [0.9999976881235857, 2.3118764144268542e-06, 0],\n","    [0.9999511580525517, 4.8841947448259925e-05, 0],\n","    [0.999168727944103, 0.0008312720558968423, 0],\n","    [0.9990082835720937, 0.0009917164279063498, 0],\n","    [0.9991634650226539, 0.0008365349773460945, 0],\n","    [0.999999937178252, 6.282174796976487e-08, 0],\n","    [0.40536672295206516, 0.5946332770479349, 1],\n","    [0.6004221486625587, 0.3995778513374413, 0],\n","    [0.9998761118556163, 0.00012388814438379092, 0]]}]}"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["deployment_id = client.deployments.get_id(deployment)\n","\n","x_predict_data = predict_data.loc[:, used_names[:-1]]\n","y_predict_data = predict_data.loc[:, used_names[-1]]\n","\n","#scoring_payload = {\n","#    \"fields\": x_predict_data.columns.values.tolist(),\n","#    \"values\": x_predict_data.values.tolist()\n","#}\n","\n","scoring_payload = {\n","    client.deployments.ScoringMetaNames.INPUT_DATA: [\n","        {\n","            'fields': x_predict_data.columns.values.tolist(),\n","            'values': x_predict_data.values.tolist()\n","        }]\n","}\n","predictions_predict_data = client.deployments.score(deployment_id, scoring_payload)\n","\n","#print(json.dumps(predictions_predict_data, indent=4))\n","predictions_predict_data"]},{"cell_type":"markdown","metadata":{},"source":["Preview some results metrics"]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy 0.95\n","Balanced accuracy 0.8333333333333333\n","Confusion Matrix [[17  0]\n"," [ 1  2]]\n"]}],"source":["label_predictions = []\n","for result in predictions_predict_data['predictions'][0].get('values'):\n","    if result[0] >= 0.5:\n","        label_predictions.append(0)\n","    elif result[0] < 0.5:\n","        label_predictions.append(1)\n","        \n","balanced_acc = balanced_accuracy_score(y_predict_data, label_predictions)\n","\n","confusion_mat = confusion_matrix(y_predict_data, label_predictions, labels=[0, 1])\n","\n","acc = accuracy_score(y_predict_data, label_predictions)\n","\n","print('Accuracy', acc)\n","print('Balanced accuracy', balanced_acc)\n","print('Confusion Matrix', confusion_mat)"]},{"cell_type":"markdown","metadata":{},"source":["<a id=\"summary\"></a>\n","## 5. Summary and next steps\n","You successfully completed this notebook!   \n","Check out the [Online Documentation](https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-samples-overview.html) for more samples, tutorials, documentation, how-tos, and blog posts. "]},{"cell_type":"markdown","metadata":{},"source":["### Authors\n","\n","This notebook was inspired by original notebook written by Pierre Feillet using Apache Spark and Watson Machine Learning.\n","It was adapted for Scikit Learn by Marine Collery."]}],"metadata":{"kernelspec":{"display_name":"Python 3.9 with Spark","language":"python3","name":"python39"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":false,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{"height":"458px","left":"10px","top":"150px","width":"212px"},"toc_section_display":true,"toc_window_display":true}},"nbformat":4,"nbformat_minor":1}
